# 📘 NLP 기초 프로젝트 2강: 텍스트 데이터 처리 및 분석

## 1. 자연어처리 과정

-   **전체 과정**: 수집 → 정제 → 훈련 → 예측 → 보완
-   **텍스트 데이터 처리 및 분석**: 수집, 정제, 훈련
-   **정량적 성능 분석**: 훈련, 예측, 보완

### 단계별 내용

-   **수집**: 웹 크롤링, 문서 추출, 뉴스, 오픈데이터, 데이터 구매
-   **정제**: 오탈자 제거, 문법 교정, 불용어/노이즈 제거, 정규화,
    토큰화
-   **훈련**: 머신러닝·딥러닝 모델 학습, 하이퍼파라미터 설정
-   **예측**: 모델 평가, 활용, 추론
-   **보완**: 데이터 품질 향상, 모델 개선, 경량화

------------------------------------------------------------------------

## 2. 텍스트 데이터 구조

-   **계층적 구조**

        말뭉치 → 문서 → 단락 → 문장 → 단어 → 형태소 → 글자(character)

-   **형태소**: 의미를 가지는 가장 작은 단위 (예: "가다" → "가", "다")

------------------------------------------------------------------------

## 3. 활용 사례

-   **텍스트 분류**: 기사 분류, 스팸 탐지, 형태소 분석
-   **텍스트 평가**: 감성 분석, 리뷰 분석, 댓글 분석
-   **텍스트 생성**: 기사 요약, 대화 생성, 문서 작성
-   **텍스트 군집화/유사도 분석**: 추천 시스템, 구매 이력 분류

------------------------------------------------------------------------

## 4. 텍스트 데이터 처리 및 분석

### (1) 수집

-   데이터 출처: SNS, 블로그, 뉴스, 공개데이터, 웹 크롤링, 데이터 구매

### (2) 전처리

-   문법 교정
-   불용어 제거
-   정제(Cleaning): 특수문자/노이즈 제거
-   정규화(Normalization): 통일된 표현으로 변환

### (3) 토큰화 (Tokenization)

-   텍스트를 의미 단위로 분리하는 과정
-   **방법**
    -   문장 기반: N-gram, Character, Word
    -   의미 기반: Morpheme(형태소)
    -   데이터 기반: Subword (BPE, WordPiece, Unigram), Hybrid

------------------------------------------------------------------------

## 5. Subword 기반 토큰화 기법

### 🔹 Byte Pair Encoding (BPE)

-   가장 자주 등장하는 글자 쌍을 하나의 토큰으로 병합
-   반복 패턴을 압축 형태로 처리 가능

### 🔹 Byte-Level BPE

-   문자 대신 바이트 단위로 병합
-   이모지·다국어 처리에 효과적

### 🔹 WordPiece

-   문자 쌍의 **Score**를 기준으로 병합
-   vocabulary가 원하는 크기에 도달하면 중단

### 🔹 Unigram

-   가능한 모든 토큰 집합에서 시작 → Loss 계산으로 불필요한 토큰 제거
-   확률 기반 토큰 선택

------------------------------------------------------------------------

## 6. 토큰화 도구

-   **Hugging Face Tokenizers**
-   **SentencePiece (Google)**
-   **OpenNMT tokenizer**
-   **tiktoken (OpenAI)**
-   **KoNLPy (한국어)**
-   **NLTK**
-   **spaCy**

------------------------------------------------------------------------

## 7. 텍스트 데이터 분석

### 기본 분석

-   데이터 목적 확인 (주제, 범위)
-   주요 단어 파악 (문자 빈도, 워드 클라우드)
-   정량적 분석 (문장 수, 길이, 토큰 분포)

### 수치 기반 기법

-   **Bag of Words (BoW)**: 단어 등장 횟수 기반
-   **TF-IDF**: 단어 중요도 가중치 반영

### Backbone Model

-   주요 언어별/도메인별 모델 (예: BERT, GPT, KLUE 등)
-   활용 목적: 분류, 평가, 번역, 질의응답 등

------------------------------------------------------------------------

## 8. NLP with DataFrame

-   **DataFrame**: 대용량 텍스트 데이터를 관리·탐색·가공하는 데 유용
    (Excel 유사)
-   **Pandas**: 시계열·표 데이터 처리, 시각화 가능
-   **활용 예시**
    -   데이터 필터링, 조건 검색
    -   특정 단어 치환
    -   apply 함수로 길이 계산, 전처리 자동화

------------------------------------------------------------------------

## 9. 정량적 성능 분석

-   **데이터 불균형**: 라벨 불균형 시 모델이 편향됨
-   **EDA**: 데이터 탐색 (길이 분포, 단어 빈도 등)
-   **Metrics**: 라벨별 성능, 문장 길이별 성능
-   **Feature 분석**: 특정 단어·레이블 관계, 오류 패턴 확인
-   **Token 분석**: 실제 입력된 토큰 확인, 잘못된 분절·UNK 처리 여부
    확인

------------------------------------------------------------------------

## 🔑 핵심 요약

1.  NLP는 **수집 → 정제 → 훈련 → 예측 → 보완**의 사이클로 반복된다.
2.  텍스트 구조는 말뭉치에서 형태소까지 **계층적 구조**를 가진다.
3.  **토큰화(Subword 기법)**는 현대 NLP 모델의 핵심이며,
    BPE·WordPiece·Unigram이 주로 사용된다.
4.  **데이터 전처리와 EDA**는 모델 성능에 직접적인 영향을 미친다.
5.  Pandas와 같은 **데이터 분석 툴**은 텍스트 처리에 필수적이다.

------------------------------------------------------------------------
