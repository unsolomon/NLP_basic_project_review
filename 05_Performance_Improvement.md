# 성능 향상 기술

------------------------------------------------------------------------
## 📌 요약

-   **모델 선별**
    -   직접 탐색, 간접 탐색
-   **하이퍼파라미터 최적화**
    -   모델 학습 과정에 영향을 주는 변수 조정
    -   WandB 등 다양한 도구 사용
-   **앙상블**
    -   다양한 모델을 결합해 최적 출력 도출
-   **PEFT**
    -   대규모 모델을 작은 디바이스에서도 활용 가능하게 만드는 기술

------------------------------------------------------------------------

## 1. 기반 모델 선택

자연어처리 문제마다 적합한 모델이 서로 다르다.

-   **직접 조사**: 보유한 데이터에 대해 직접 실험 후 최적의 모델을 선정
    (비교적 작고 가벼운 모델에 대해서 진행)
-   **간접 조사**: 유사한 데이터에 대한 외부 실험 검토, 최적의 모델 선정
    (사용하고자 하는 도메인과 유사한 벤치마크 참고)

**간접 조사 고려사항** - 언어 처리 능력 - 도메인 유사성 - 출력 형태

------------------------------------------------------------------------

## 2. 하이퍼파라미터 최적화

하이퍼파라미터: 기계 학습 모델 훈련을 관리하는 외부 구성 변수.
훈련 시 모델 가중치 업데이트에 영향을 줌.

### 주요 도구

* **Scikit-Learn**
  * GridSearchCV (모든 조합 탐색)
  * RandomizedSearchCV (랜덤 조합 탐색)
* **Hyperopt**
  * Bayesian Optimization 기반 탐색
* **Optuna**
  * Sequential Model-Based Optimization (SMBO)
* **WandB Sweep**
  * 하이퍼파라미터 탐색과 시각화 지원(설치: `!pip install wandb`)


------------------------------------------------------------------------

## 3. 앙상블 기법

-   **Voting**: 여러 모델의 예측을 투표 방식으로 결합하여 최종 예측 결정
-   **Bagging**: 데이터를 여러 번 샘플링하여 여러 모델 학습 후
    평균/다수결 결정 (예: Random Forest)
-   **Boosting**: 약한 학습기를 순차적으로 학습시켜 강한 학습기 생성
    (예: AdaBoost, Gradient Boosting)

**응용** - **N21, N2N**: Voting, Bagging, Boosting - **N21, N2N, N2M**:
Average Log-probability, Router, Mixture of Experts (MoE)

**세부** - **Average Log-probability**: 여러 모델의 로그 확률을 평균 -
**Mixture of Experts (MoE)**: 입력 데이터의 특정 부분을 다른 전문가
모델이 처리 - **Router**: 입력에 따라 적절한 모델을 선택하는 분류기

------------------------------------------------------------------------

## 4. Parameter Efficient Fine Tuning (PEFT)

-   **Prefix Tuning**
    -   일반 Fine tuning 대신 Prefix를 적용
    -   하나의 Task에 대해 일부 레이어만 튜닝
-   **LoRA (Low-Rank Adaptation)**
    -   Pretrained 모델 파라미터는 고정, 외부 파라미터만 학습
    -   전체 모델 재학습 없이 특정 작업에 맞게 빠르고 효과적으로 튜닝
-   **ReFT (Representation Fine-tuning)**
    -   Parameter를 직접 건드리지 않고 Hidden states 보정
    -   Hidden states에 행렬을 적용하여 추가 성능 향상 가능
    -   LoRA와 병행 가능

------------------------------------------------------------------------

